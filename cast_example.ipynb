{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve the VNC dataset, you need to instantiate a neuprint Client, using the API key given to you when you sign up with a google account. \n",
    "\n",
    "As of June 07 2023, the MANC (manc:v1.0) or male VNC dataset is publicly available at https://neuprint.janelia.org/. To use this dataset see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuprint import Client\n",
    "\n",
    "MANC_client = Client('neuprint.janelia.org', dataset='manc:v1.0', token='Your-API-Key')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The client essentially acts as a bridge between the specific database and the API, so we can also create a client object for the hemibrain dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemibrain_client = Client('neuprint.janelia.org', dataset='hemibrain:v1.2.1', token='Your-API-Key')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing/Storage\n",
    "A wrapper class, ConnDF, provided within data_processing.py provides the core data import, storage and processing functions. \n",
    "\n",
    "Different instances of ConnDF can be made which parallel the client. i.e.) One instance for the MANC dataset, and one for the hemibrain dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import ConnDF\n",
    "\n",
    "# Here you would pass in the MANC_client you created above. \n",
    "MANC_data = ConnDF(client=MANC_client)\n",
    "# Instead you pass in the hemibrain_client. \n",
    "hemibrain_data = ConnDF(client=hemibrain_client)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connectome datasets can be retrieved everytime an instance of ConnDF is called, however downloading this takes a long time. The datasets themselves come in the form of three .csvs, which are not that large in size, so storing this to local disk and then loading it is a more viable option. This is provided as an option for the function for loading/downloading the datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset, simply call the extract_full() method of your ConnDF instance with no parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANC_data.extract_full()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will retrieve all neuron metadata and all 'Traced' connections in the dataset, then save it to a default path in the current working directory (using the default path defined by neuprint.fetch_adjacencies). Using this path, one can then reload the dataset in future sessions by calling extract_full(file_path='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANC_data.extract_full(file_path='default') # Throws "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the dataset, call the extract_full() method again, which redownloads the latest dataset and overwrites the .csvs in the default path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANC_data.extract_full()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing/Filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available processing and filtering methods are a set of wrapped pandas queries and operations for convenience and particular use in the analyses and simulations performed by other packages of the CAST toolbox. These operate on variables of ConnDF instances which store the neuron metadata dataframe in neuron_master and connection edgelist dataframe in conn_master. Any filtering or processing step is performed on a copy of the conn_master dataframe, stored in conn_filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access the neuron metadata dataframe:\n",
    "MANC_data.neuron_master\n",
    "\n",
    "# To access the connection edgelist dataframe:\n",
    "MANC_data.conn_master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurort3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
